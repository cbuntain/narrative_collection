{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import gzip\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<img src=\"http://www.cs.umd.edu/~cbuntain/inst728e/TwitterLogo.png\" width=\"20%\">\n",
    "\n",
    "## Twitter API\n",
    "\n",
    "Twitter's API is most useful and flexible but takes several steps to configure. \n",
    "To get access to the API, you first need to have a Twitter account and have a mobile phone number (or any number that can receive text messages) attached to that account.\n",
    "Then, we'll use Twitter's developer portal to create an \"app\" that will then give us the keys tokens and keys (essentially IDs and passwords) we will need to connect to the API.\n",
    "\n",
    "So, in summary, the general steps are:\n",
    "\n",
    "0. Have a Twitter account,\n",
    "1. Configure your Twitter account with your mobile number,\n",
    "2. Create an app on Twitter's developer site, and\n",
    "3. Generate consumer and access keys and secrets.\n",
    "\n",
    "We will then plug these four strings into the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our first piece of code, we need to import the package \n",
    "# that connects to Twitter. Tweepy is a popular and fully featured\n",
    "# implementation.\n",
    "\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the strings from your Twitter app webpage to populate these four \n",
    "# variables. Be sure and put the strings BETWEEN the quotation marks\n",
    "# to make it a valid Python string.\n",
    "\n",
    "consumer_key = \"\"\n",
    "consumer_secret = \"\"\n",
    "access_token = \"\"\n",
    "access_secret = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to Twitter\n",
    "\n",
    "Once we have the authentication details set, we can connect to Twitter using the Tweepy OAuth handler, as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Twitter!\n"
     ]
    }
   ],
   "source": [
    "# Now we use the configured authentication information to connect\n",
    "# to Twitter's API\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "print(\"Connected to Twitter!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our Connection\n",
    "\n",
    "Now that we are connected to Twitter, let's do a brief check that we can read tweets by pulling the first few tweets from our own timeline (or the account associated with your Twitter app) and printing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmmaLBriant Dr Emma L Briant said: RT @JolyonMaugham: Under pressure, the Govt has finally published the text of its (failed) application for permission to appeal to the Supr…\n",
      "techreview MIT Technology Review said: Technology is ever-changing. Let our newsletters be a constant. Sign up for free today! https://t.co/T16PbXzckJ\n",
      "emrek Emre Kıcıman said: Looking forward #EuroCSS 2018 at Cologne just around the corner.  My talk is titled \"Where Does Data Bias Come from… https://t.co/k0sr0QjtOo\n",
      "j363j j363j said: #ImpeachTrump #KushnerResign #DeposeMohammedBinSalman\n",
      "#KhashoggiMurder https://t.co/Zn1VS3NSYx\n",
      "EmmaLBriant Dr Emma L Briant said: RT @WSJ: \"I felt that my face was burning, and my baby fainted. I ran for my life and that of my children,\" said Cindy Milla, a 23-year-old…\n"
     ]
    }
   ],
   "source": [
    "# Get tweets from our timeline\n",
    "public_tweets = api.home_timeline()\n",
    "\n",
    "# print the first five authors and tweet texts\n",
    "for tweet in public_tweets[:5]:\n",
    "    print (tweet.author.screen_name, tweet.author.name, \"said:\", tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Pages\n",
    "\n",
    "As mentioned, Twitter serves results in pages. \n",
    "To get all results, we can use Tweepy's Cursor implementation, which handles this iteration through pages for us in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'codybuntain'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me = api.me()\n",
    "me.screen_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handler for waiting if we exhaust a rate limit\n",
    "def limit_handled(cursor, get_resource = lambda x: x['statuses']['/statuses/lookup']):\n",
    "    while True:\n",
    "        try:\n",
    "            yield cursor.next()\n",
    "        except tweepy.RateLimitError:\n",
    "            # Determine how long we need to wait...\n",
    "            s = api.rate_limit_status()\n",
    "            dif = get_resource(s[\"resources\"])['reset'] - int(time.time())\n",
    "            \n",
    "            # If we have a wait time, wait for it\n",
    "            if ( dif > 0 ):\n",
    "                print(\"Sleeping for %d seconds...\" % dif)\n",
    "                time.sleep(dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ids(filename):\n",
    "    with gzip.open(filename, \"rb\") as in_file:\n",
    "        for line_bytes in in_file:\n",
    "            line = line_bytes.decode(\"utf8\").strip()\n",
    "            \n",
    "            if ( len(line) == 0 ):\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                tweet = json.loads(line)\n",
    "\n",
    "                yield int(tweet[\"ID\"])\n",
    "            except:\n",
    "                print(line)\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rehydrator(id_slice):\n",
    "    rehydrated = None\n",
    "    while True:\n",
    "        try:\n",
    "            rehydrated = api.statuses_lookup(id_slice)\n",
    "            break\n",
    "        except tweepy.RateLimitError:\n",
    "            # Determine how long we need to wait...\n",
    "            s = api.rate_limit_status()\n",
    "            dif = s[\"resources\"]['statuses']['/statuses/lookup']['reset'] - int(time.time())\n",
    "\n",
    "            # If we have a wait time, wait for it\n",
    "            if ( dif > 0 ):\n",
    "                print(\"Sleeping for %d seconds...\" % dif)\n",
    "                time.sleep(dif)\n",
    "    return rehydrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_set = set()\n",
    "id_slice = []\n",
    "slice_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping for 112 seconds...\n",
      "Sleeping for 387 seconds...\n",
      "Sleeping for 900 seconds...\n",
      "Sleeping for 406 seconds...\n",
      "Sleeping for 394 seconds...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(\"output.json\", \"w\") as out_file:\n",
    "    for tid in get_ids(\"tweets.json.gz\"):\n",
    "        if ( tid not in id_set and tid not in id_slice ):\n",
    "            id_slice.append(tid)\n",
    "\n",
    "        if ( len(id_slice) >= slice_size ):\n",
    "            # rehydrate\n",
    "            rehydrated = rehydrator(id_slice)\n",
    "\n",
    "            # add to list of pulled tweets\n",
    "            for tweet in rehydrated:\n",
    "                id_set.add(tweet.id)\n",
    "                out_file.write(\"%s\\n\" % json.dumps(tweet._json))\n",
    "\n",
    "            # Clear id list\n",
    "            id_slice = []\n",
    "            \n",
    "    # Pull any remaining IDs\n",
    "    if ( len(id_slice) > 0 ):\n",
    "        # rehydrate\n",
    "        rehydrated = rehydrator(id_slice)\n",
    "\n",
    "        # add to list of pulled tweets\n",
    "        for tweet in rehydrated:\n",
    "            id_set.add(tweet.id)\n",
    "            out_file.write(\"%s\\n\" % json.dumps(tweet._json))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/apps/anaconda3/4.3.1/lib/python3.6/site-packages/ipykernel/__main__.py:3: DeprecationWarning: generator 'limit_handled' raised StopIteration\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "total_tweets = 3200\n",
    "tweet_json = []\n",
    "for tweet in limit_handled(tweepy.Cursor(api.user_timeline, id=\"cphfashsummit\", count=3200).items(total_tweets), get_resource = lambda x: x['statuses']['/statuses/user_timeline']):\n",
    "    tweet_json.append(json.dumps(tweet._json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cphfashsummit_direct_tweets.json\", \"w\") as out_file:\n",
    "    for tweet_str in tweet_json:\n",
    "        out_file.write(\"%s\\n\" % tweet_str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1476 903\n",
      "573\n",
      "1063521323647934464\n"
     ]
    }
   ],
   "source": [
    "ret_user_ids = set()\n",
    "with open(\"cphfashsummit_direct_tweets.json\", \"r\") as in_file:\n",
    "    for line in in_file:\n",
    "        tweet = json.loads(line)\n",
    "        ret_user_ids.add(tweet[\"id\"])\n",
    "        \n",
    "scrape_user_ids = set()\n",
    "with open(\"cphfashsummit_tweets.json/part-00000\", \"r\") as in_file:\n",
    "    for line in in_file:\n",
    "        tweet = json.loads(line)\n",
    "        scrape_user_ids.add(tweet[\"id\"])\n",
    "        \n",
    "print(len(ret_user_ids), len(scrape_user_ids))\n",
    "print(len(ret_user_ids.difference(scrape_user_ids)))\n",
    "print(list(ret_user_ids.difference(scrape_user_ids))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "g = nx.Graph()\n",
    "\n",
    "target = \"codybuntain\"\n",
    "total_friends = 20\n",
    "\n",
    "# Get the first few friends of mine and first few of each of them\n",
    "#  and add their links to the graph\n",
    "for friend in limit_handled(tweepy.Cursor(api.friends, id=target).items(total_friends)):\n",
    "    g.add_node(friend.screen_name)\n",
    "    g.add_edge(target, friend.screen_name)\n",
    "    print(\"Processing:\", friend.screen_name)\n",
    "    \n",
    "    for friend_of_friend in limit_handled(tweepy.Cursor(api.friends, id=friend.screen_name).items(total_friends), get_resource = lambda x: x['friends']['/friends/list']):\n",
    "        g.add_node(friend_of_friend.screen_name)\n",
    "        g.add_edge(friend.screen_name, friend_of_friend.screen_name)\n",
    "        print(\"\\t->\", friend_of_friend.screen_name)\n",
    "        \n",
    "subs = [x[0] for x in g.degree() if x[1] > 0]\n",
    "nx.draw(nx.subgraph(g, subs))\n",
    "\n",
    "nx.write_graphml(g, \"twitter_codybuntain.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "763461"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_ids = []\n",
    "with open(\"rehydrated.json\", \"r\") as in_file:\n",
    "    for line in in_file:\n",
    "        tweet = json.loads(line)\n",
    "        tweet_id = tweet[\"id\"]\n",
    "        \n",
    "        if ( tweet_id not in id_set ):\n",
    "            missing_ids.append(tweet_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clb617/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: generator 'limit_handled' raised StopIteration\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "total_likes = 3200\n",
    "tweet_json = []\n",
    "for tweet in limit_handled(tweepy.Cursor(api.favorites, id=\"codybuntain\", count=3200).items(total_likes), get_resource = lambda x: x['favorites']['/favorites/list']):\n",
    "    tweet_json.append(json.dumps(tweet._json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2979"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"created_at\": \"Thu Jun 27 21:52:32 +0000 2013\", \"id\": 350371093418221568, \"id_str\": \"350371093418221568\", \"text\": \"@proteius ugh gross!\", \"truncated\": false, \"entities\": {\"hashtags\": [], \"symbols\": [], \"user_mentions\": [], \"urls\": []}, \"source\": \"<a href=\\\\\"http://twitter.com/download/android\\\\\" rel=\\\\\"nofollow\\\\\">Twitter for Android</a>\", \"in_reply_to_status_id\": null, \"in_reply_to_status_id_str\": null, \"in_reply_to_user_id\": 363200844, \"in_reply_to_user_id_str\": \"363200844\", \"in_reply_to_screen_name\": \"codybuntain\", \"user\": {\"id\": 14522676, \"id_str\": \"14522676\", \"name\": \"s\", \"screen_name\": \"sanapants\", \"location\": \"bay area\", \"description\": \"pretty awesome\", \"url\": \"http://t.co/WxIMc9YkcR\", \"entities\": {\"url\": {\"urls\": [{\"url\": \"http://t.co/WxIMc9YkcR\", \"expanded_url\": \"http://www.last.fm/user/sanana\", \"display_url\": \"last.fm/user/sanana\", \"indices\": [0, 22]}]}, \"description\": {\"urls\": []}}, \"protected\": true, \"followers_count\": 74, \"friends_count\": 142, \"listed_count\": 1, \"created_at\": \"Fri Apr 25 04:55:45 +0000 2008\", \"favourites_count\": 592, \"utc_offset\": null, \"time_zone\": null, \"geo_enabled\": true, \"verified\": false, \"statuses_count\": 4573, \"lang\": \"en\", \"contributors_enabled\": false, \"is_translator\": false, \"is_translation_enabled\": false, \"profile_background_color\": \"F8F4D7\", \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme1/bg.png\", \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme1/bg.png\", \"profile_background_tile\": true, \"profile_image_url\": \"http://pbs.twimg.com/profile_images/806946285861224449/pm8PN4xc_normal.jpg\", \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/806946285861224449/pm8PN4xc_normal.jpg\", \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/14522676/1398205646\", \"profile_link_color\": \"949494\", \"profile_sidebar_border_color\": \"000000\", \"profile_sidebar_fill_color\": \"E98976\", \"profile_text_color\": \"F4DEC2\", \"profile_use_background_image\": true, \"has_extended_profile\": true, \"default_profile\": false, \"default_profile_image\": false, \"following\": true, \"follow_request_sent\": false, \"notifications\": false, \"translator_type\": \"none\"}, \"geo\": {\"type\": \"Point\", \"coordinates\": [40.7240438, -73.997216]}, \"coordinates\": {\"type\": \"Point\", \"coordinates\": [-73.997216, 40.7240438]}, \"place\": {\"id\": \"086752cb03de1d5d\", \"url\": \"https://api.twitter.com/1.1/geo/id/086752cb03de1d5d.json\", \"place_type\": \"city\", \"name\": \"Manhattan\", \"full_name\": \"Manhattan, NY\", \"country_code\": \"US\", \"country\": \"United States\", \"contained_within\": [], \"bounding_box\": {\"type\": \"Polygon\", \"coordinates\": [[[-74.047285, 40.679548], [-73.907, 40.679548], [-73.907, 40.882214], [-74.047285, 40.882214]]]}, \"attributes\": {}}, \"contributors\": null, \"is_quote_status\": false, \"retweet_count\": 0, \"favorite_count\": 1, \"favorited\": true, \"retweeted\": false, \"lang\": \"en\"}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_json[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clb617/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: generator 'limit_handled' raised StopIteration\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "total_likes = 3200\n",
    "tweet_json = []\n",
    "for tweet in limit_handled(tweepy.Cursor(api.favorites, id=\"j_a_tucker\", count=3200).items(total_likes), get_resource = lambda x: x['favorites']['/favorites/list']):\n",
    "    tweet_json.append(json.dumps(tweet._json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1754"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
